# Automated Accessibility Testing Coverage Analysis

## Executive Summary

This document provides a comprehensive analysis of what percentage of WCAG issues can be detected through automated accessibility testing tools like axe-core. Understanding these capabilities and limitations is crucial for honest product positioning and setting realistic customer expectations.

### Key Metrics At a Glance

| Measurement Approach | Coverage Rate | Source |
|---------------------|---------------|--------|
| **By Real-World Issues** | **57%** | Deque Study (2,000+ audits, 300K issues) |
| **By WCAG Criteria (Full)** | **13%** | Accessible.org Analysis |
| **By WCAG Criteria (Partial)** | **45%** | Accessible.org Analysis |
| **Combined with Guided Tests** | **80%** | Deque Research |

### Why the Discrepancy?

The 57% vs 13-30% difference exists because:
- Some issue types occur **much more frequently** than others
- Contrast issues alone account for **30% of all accessibility issues**
- These high-frequency issues happen to be **highly automatable**

---

## 1. Coverage Breakdown by Automation Capability

### WCAG 2.2 Level AA (55 Success Criteria)

| Category | Count | Percentage | Description |
|----------|-------|------------|-------------|
| ‚úÖ **Mostly Accurate** | 7 | 13% | Fully automatable with high accuracy |
| ‚ö†Ô∏è **Partially Detectable** | 25 | 45% | Can detect existence, not quality/meaning |
| ‚ùå **Not Detectable** | 23 | 42% | Requires human judgment |

---

## 2. Detailed Breakdown by Category

### ‚úÖ Mostly Accurate Detection (13% - 7 Criteria)

These criteria involve technical, measurable requirements where automated scans rarely produce false positives.

| WCAG SC | Name | What Automation Tests |
|---------|------|----------------------|
| 1.4.3 | Contrast (Minimum) | Color contrast ratio calculation (‚â•4.5:1) |
| 2.4.2 | Page Titled | Presence and non-empty `<title>` element |
| 3.1.1 | Language of Page | Presence of valid `lang` attribute on `<html>` |
| 1.3.5 | Identify Input Purpose | Valid `autocomplete` attribute values |
| 1.4.11 | Non-text Contrast | UI component contrast ratio (‚â•3:1) |
| 2.5.8 | Target Size (Minimum) | Click/touch target dimensions (‚â•24x24px) |
| 2.4.1 | Bypass Blocks | Presence of skip links or landmark regions |

### ‚ö†Ô∏è Partially Detectable (45% - 25 Criteria)

These criteria can be partially tested - automation detects presence but cannot evaluate quality, meaning, or appropriateness.

| WCAG SC | Name | ‚úÖ Can Detect | ‚ùå Cannot Detect |
|---------|------|---------------|------------------|
| 1.1.1 | Non-text Content | Alt text exists | Alt text accurately describes content |
| 1.3.1 | Info and Relationships | Proper HTML markup (headings, lists, tables) | Logical structure and relationships |
| 2.1.1 | Keyboard | Elements are focusable | Navigation order is logical |
| 2.4.4 | Link Purpose | Link text exists | Link text is meaningful in context |
| 4.1.2 | Name, Role, Value | ARIA attributes are valid | Accessible names are appropriate |
| 1.4.4 | Resize Text | CSS uses flexible units | Text remains readable when zoomed |
| 2.4.7 | Focus Visible | Focus styles exist | Focus is sufficiently visible |
| 1.4.10 | Reflow | Content structure | Content reflows properly at 320px |
| 2.5.1 | Pointer Gestures | Gesture handlers exist | Single-pointer alternatives exist |
| 3.3.1 | Error Identification | Error states exist | Errors are clearly identified |
| 3.3.2 | Labels or Instructions | Labels exist | Labels are clear and helpful |

### ‚ùå Not Detectable (42% - 23 Criteria)

These criteria require human judgment about quality, meaning, context, or user experience.

| WCAG SC | Name | Why Automation Fails |
|---------|------|---------------------|
| 1.2.2 | Captions (Prerecorded) | Cannot verify caption accuracy or synchronization |
| 1.2.3 | Audio Description or Media Alternative | Cannot evaluate if descriptions convey visual information |
| 1.2.5 | Audio Description (Prerecorded) | Cannot assess audio description completeness |
| 1.3.2 | Meaningful Sequence | Cannot verify reading order is logical |
| 1.3.3 | Sensory Characteristics | Cannot evaluate if instructions rely solely on sensory info |
| 2.4.5 | Multiple Ways | Cannot assess navigation method variety |
| 2.4.6 | Headings and Labels | Cannot verify headings describe content |
| 3.2.3 | Consistent Navigation | Requires cross-page comparison |
| 3.2.4 | Consistent Identification | Requires cross-page comparison |
| 3.3.3 | Error Suggestion | Cannot evaluate if suggestions are helpful |
| 3.3.4 | Error Prevention (Legal, Financial, Data) | Cannot assess prevention mechanism adequacy |
| 1.4.5 | Images of Text | Cannot determine if image text is necessary |
| 2.2.1 | Timing Adjustable | Cannot verify all timing mechanisms |
| 2.3.1 | Three Flashes or Below Threshold | Limited flash detection capability |

---

## 3. Top Issues Detected by Automated Testing

### Data from Deque Study (2,000+ Audits, 13,000+ Pages, ~300,000 Issues)

| Rank | WCAG SC | Issue Name | % of All Issues | Cumulative % | Automatable |
|------|---------|------------|-----------------|--------------|-------------|
| 1 | 1.4.3 | Contrast (Minimum) | **30.08%** | 30.08% | ‚úÖ Fully |
| 2 | 4.1.2 | Name, Role, Value | **16.37%** | 46.45% | ‚ö†Ô∏è Partially |
| 3 | 1.3.1 | Info and Relationships | **12.33%** | 58.78% | ‚ö†Ô∏è Partially |
| 4 | 4.1.1 | Parsing* | **11.69%** | 70.47% | ‚úÖ Fully |
| 5 | 1.1.1 | Non-text Content | **8.04%** | 78.51% | ‚ö†Ô∏è Partially |
| 6 | 2.4.4 | Link Purpose | **4.21%** | 82.72% | ‚ö†Ô∏è Partially |
| 7 | 1.3.5 | Identify Input Purpose | **3.15%** | 85.87% | ‚úÖ Fully |

*Note: 4.1.1 Parsing has been removed in WCAG 2.2*

### Key Insight

> **Top 5 issues account for 78.51% of all accessibility issues found.**
>
> Of these top 5:
> - 2 are fully automatable
> - 3 are partially automatable
>
> This explains why axe-core achieves 57% real-world coverage despite only fully testing ~13% of WCAG criteria.

---

## 4. axe-core Rules Inventory

### Rules by WCAG Version/Level

| Category | Rule Count | Examples |
|----------|------------|----------|
| WCAG 2.0 Level A | ~25 | `image-alt`, `html-has-lang`, `document-title`, `bypass` |
| WCAG 2.0 Level AA | ~15 | `color-contrast`, `meta-refresh`, `valid-lang` |
| WCAG 2.1 Level A | ~5 | `orientation`, `label-content-name-mismatch` |
| WCAG 2.1 Level AA | ~5 | `autocomplete-valid`, `avoid-inline-spacing` |
| WCAG 2.2 Level AA | ~3 | `target-size` (disabled by default) |
| Best Practices | ~30 | `heading-order`, `landmark-*`, `skip-link` |

### Rules by Category

#### Images & Alternative Text
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `image-alt` | `<img>` elements must have alt text | 1.1.1 |
| `area-alt` | Image map `<area>` elements must have alt text | 1.1.1 |
| `input-image-alt` | Image buttons must have alt text | 1.1.1 |
| `svg-img-alt` | SVG elements with img role must have accessible text | 1.1.1 |
| `object-alt` | `<object>` elements must have alt text | 1.1.1 |
| `role-img-alt` | Elements with `role="img"` must have alt text | 1.1.1 |

#### Forms & Input
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `label` | Form elements must have labels | 1.3.1, 4.1.2 |
| `select-name` | Select elements must have accessible names | 4.1.2 |
| `button-name` | Buttons must have discernible text | 4.1.2 |
| `input-button-name` | Input buttons must have discernible text | 4.1.2 |
| `autocomplete-valid` | Autocomplete attribute values must be valid | 1.3.5 |

#### Color & Contrast
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `color-contrast` | Text must meet minimum contrast ratio (4.5:1) | 1.4.3 |
| `color-contrast-enhanced` | Text must meet enhanced contrast ratio (7:1) | 1.4.6 (AAA) |
| `link-in-text-block` | Links in text must be distinguishable | 1.4.1 |

#### ARIA Implementation
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `aria-allowed-attr` | ARIA attributes must be allowed for element's role | 4.1.2 |
| `aria-required-attr` | Required ARIA attributes must be present | 4.1.2 |
| `aria-required-children` | ARIA parent roles must contain required children | 1.3.1 |
| `aria-required-parent` | ARIA child roles must have required parent | 1.3.1 |
| `aria-roles` | ARIA role values must be valid | 4.1.2 |
| `aria-valid-attr` | ARIA attribute names must be valid | 4.1.2 |
| `aria-valid-attr-value` | ARIA attribute values must be valid | 4.1.2 |
| `aria-hidden-focus` | aria-hidden elements must not be focusable | 4.1.2 |

#### Document Structure
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `document-title` | Document must have a non-empty `<title>` | 2.4.2 |
| `html-has-lang` | `<html>` element must have a lang attribute | 3.1.1 |
| `html-lang-valid` | `<html>` lang attribute must be valid | 3.1.1 |
| `valid-lang` | lang attributes must have valid values | 3.1.2 |
| `bypass` | Page must have means to bypass repeated blocks | 2.4.1 |
| `frame-title` | `<frame>` and `<iframe>` must have title | 2.4.1 |

#### Tables
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `table-fake-caption` | Data tables should not use caption element incorrectly | 1.3.1 |
| `td-headers-attr` | Table cells must reference proper headers | 1.3.1 |
| `th-has-data-cells` | Table headers must have associated data cells | 1.3.1 |
| `scope-attr-valid` | scope attribute must be used correctly | 1.3.1 |

#### Lists
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `list` | `<ul>` and `<ol>` must only contain `<li>`, `<script>`, or `<template>` | 1.3.1 |
| `listitem` | `<li>` must be contained in `<ul>` or `<ol>` | 1.3.1 |
| `definition-list` | `<dl>` must only contain `<dt>` and `<dd>` groups | 1.3.1 |
| `dlitem` | `<dt>` and `<dd>` must be in a `<dl>` | 1.3.1 |

#### Navigation & Focus
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `tabindex` | tabindex should not be greater than 0 | 2.4.3 |
| `focus-order-semantics` | Focus order should be logical | 2.4.3 |
| `skip-link` | Skip link target must exist | 2.4.1 |

#### Timing & Motion
| Rule ID | Description | WCAG SC |
|---------|-------------|---------|
| `meta-refresh` | Timed refresh must not exist | 2.2.1 |
| `meta-viewport` | Zooming and scaling must not be disabled | 1.4.4 |

---

## 5. Coverage Matrix by POUR Principles

### Perceivable

| Guideline | Auto Coverage | Details |
|-----------|---------------|---------|
| 1.1 Text Alternatives | **60%** | Detects existence, not quality |
| 1.2 Time-based Media | **10%** | Only detects media presence |
| 1.3 Adaptable | **50%** | Detects markup, not logical structure |
| 1.4 Distinguishable | **70%** | Contrast excellent, resize limited |

### Operable

| Guideline | Auto Coverage | Details |
|-----------|---------------|---------|
| 2.1 Keyboard Accessible | **40%** | Detects focusable, not usability |
| 2.2 Enough Time | **30%** | Detects meta refresh, not all timing |
| 2.3 Seizures and Physical Reactions | **20%** | Limited flash detection |
| 2.4 Navigable | **50%** | Titles/skip links good; order poor |
| 2.5 Input Modalities | **40%** | Target size yes; gestures limited |

### Understandable

| Guideline | Auto Coverage | Details |
|-----------|---------------|---------|
| 3.1 Readable | **70%** | Language attributes excellent |
| 3.2 Predictable | **20%** | Requires multi-page analysis |
| 3.3 Input Assistance | **30%** | Labels yes; error messages no |

### Robust

| Guideline | Auto Coverage | Details |
|-----------|---------------|---------|
| 4.1 Compatible | **80%** | Parsing, ARIA validation excellent |

---

## 6. What Automated Testing Cannot Do

### Fundamental Limitations

1. **Cannot Understand Context or Meaning**
   - Alt text accuracy
   - Link text appropriateness
   - Heading descriptiveness
   - Error message helpfulness

2. **Cannot Evaluate User Experience**
   - Navigation flow logic
   - Reading order sensibility
   - Focus order appropriateness
   - Cognitive load

3. **Cannot Compare Across Pages**
   - Navigation consistency
   - Identification consistency
   - Help location consistency

4. **Cannot Assess Multimedia Quality**
   - Caption accuracy and synchronization
   - Audio description completeness
   - Transcript accuracy

5. **Cannot Evaluate Dynamic Behavior**
   - All timing mechanisms
   - Complex gesture alternatives
   - Live region appropriateness

### Examples of Common Misses

| What Automation Sees | What It Misses |
|---------------------|----------------|
| Alt text exists | Alt says "IMG_2847.jpg" instead of describing content |
| Heading tags present | Headings used for styling, not structure |
| Form labels exist | Labels are confusing or misleading |
| Skip link present | Skip link doesn't work or goes to wrong location |
| ARIA attributes valid | ARIA is unnecessary or incorrectly applied |
| Color contrast passes | Information conveyed by color alone |

---

## 7. Comparison: By Criteria vs By Volume

### Why Both Metrics Matter

```
By WCAG Criteria: ~30% automatable
By Issue Volume:  ~57% automatable

The difference matters for positioning:

‚úÖ For CUSTOMERS: "Catches 57% of issues" is accurate and compelling
‚úÖ For COMPLIANCE: "Covers ~30% of criteria fully" sets correct expectations
‚úÖ For HONESTY: "Manual testing still required" is always true
```

### Recommended Messaging Framework

| Audience | Message |
|----------|---------|
| **Marketing** | "Automatically detect 57% of accessibility issues" |
| **Technical** | "Tests ~30% of WCAG criteria fully, ~45% partially" |
| **Compliance** | "Essential first step; combine with manual testing for full compliance" |
| **Enterprise** | "Shift-left strategy: catch majority of issues early in development" |

---

## 8. Recommendations for Product Development

### MVP Feature Set (Fully Automatable)

**Priority 1: High-Frequency Issues**
1. ‚úÖ Color contrast checker (30% of all issues)
2. ‚úÖ Missing alt text detector
3. ‚úÖ ARIA validator
4. ‚úÖ Form label checker
5. ‚úÖ HTML lang validator
6. ‚úÖ Page title checker
7. ‚úÖ Skip navigation detector

### Phase 2: Partially Automatable with Guidance

**Detection + Manual Review Prompts**
1. ‚ö†Ô∏è Heading structure analysis + review prompts
2. ‚ö†Ô∏è Link text evaluation + suggestions
3. ‚ö†Ô∏è Keyboard navigation + focus order hints
4. ‚ö†Ô∏è Touch target size checker
5. ‚ö†Ô∏è ARIA usage appropriateness warnings

### Phase 3: Guided Manual Testing

**Structured Checklists & Workflows**
1. üìã Alt text quality checklist
2. üìã Caption verification workflow
3. üìã Reading order testing guide
4. üìã Navigation consistency audit template
5. üìã Cognitive accessibility review guide

### Phase 4: Combined Coverage (Target: 80%)

**Intelligent Guided Tests (IGT)**
1. üéØ Semi-automated tests with human verification steps
2. üéØ AI-assisted suggestions for manual review items
3. üéØ Cross-page analysis for consistency checks
4. üéØ Integration with screen reader testing

---

## 9. Honest Product Positioning

### Recommended Copy

```markdown
## What Our Tool Does

üìä **Automatically detects 57% of accessibility issues**
Based on analysis of 300,000+ real-world issues

### We Can Fully Test:
‚úÖ Color contrast (accounts for 30% of all issues)
‚úÖ Missing alternative text
‚úÖ Form labeling issues
‚úÖ ARIA implementation errors
‚úÖ Document structure problems
‚úÖ Navigation mechanism presence

### We Partially Test (detection + guidance):
‚ö†Ô∏è Heading structure (detects issues, you verify appropriateness)
‚ö†Ô∏è Link text (flags potential problems, you confirm meaning)
‚ö†Ô∏è Keyboard accessibility (identifies gaps, you test flow)

### What Requires Manual Testing:
‚ùå Alt text quality and accuracy
‚ùå Caption and audio description quality
‚ùå Reading order logic
‚ùå Navigation consistency across pages
‚ùå Error message helpfulness
‚ùå Overall user experience

### Why This Matters:
We believe in honesty. Automated testing is essential but not sufficient.
Full WCAG compliance requires automated testing + manual review + user testing.
We help you catch the majority of issues early, saving time and money.
```

---

## 10. Sources & References

### Primary Research
- [Deque - Automated Testing Identifies 57%](https://www.deque.com/blog/automated-testing-study-identifies-57-percent-of-digital-accessibility-issues/)
- [Deque - Accessibility Coverage Report (PDF)](https://accessibility.deque.com/hubfs/Accessibility-Coverage-Report.pdf)
- [Accessible.org - Scans Reliably Flag 13% of WCAG](https://accessible.org/automated-scans-wcag/)

### Technical Documentation
- [axe-core Rule Descriptions (GitHub)](https://github.com/dequelabs/axe-core/blob/develop/doc/rule-descriptions.md)
- [axe-core ACT Implementation (W3C)](https://www.w3.org/WAI/standards-guidelines/act/implementations/axe-core/)
- [W3C - Understanding Test Rules for WCAG 2.2](https://www.w3.org/WAI/WCAG22/Understanding/understanding-act-rules.html)

### Industry Analysis
- [UK Gov - What We Found Testing Tools](https://accessibility.blog.gov.uk/2017/02/24/what-we-found-when-we-tested-tools-on-the-worlds-least-accessible-webpage/)
- [BOIA - What Automated Tools Can Find](https://www.boia.org/blog/what-can-automated-accessibility-testing-tools-find)
- [Adrian Roselli - Comparing Manual and Automated Reviews](https://adrianroselli.com/2023/01/comparing-manual-and-free-automated-wcag-reviews.html)
- [UsableNet - Automated WCAG Testing is Not Enough](https://blog.usablenet.com/automated-wcag-testing-is-not-enough-for-web-accessibility-ada-compliance)

### Standards
- [WCAG 2.2 Specification (W3C)](https://www.w3.org/TR/WCAG22/)
- [W3C - WCAG 2 Overview](https://www.w3.org/WAI/standards-guidelines/wcag/)
- [W3C - What's New in WCAG 2.2](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-22/)

---

*Document Version: 1.0*
*Last Updated: December 2024*
*Author: Research Team*
